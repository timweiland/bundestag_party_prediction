{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1db0954a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mattia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import textstat\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a362510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "teststring = 'schäden erbringen .  Ja , wenn das für Sie alles bekannt war , wie konnte dann ein so kluger Mann wie Ihr Kanzlerkandidat von einem guten Investitionsstandort sprechen ? Diesen Zwiespalt und Widerspruch in Ihrer Argumentation verstehe ich nicht . Die Infrastruktur muss praktisch von Grund auf überholt werden . So ist das völlig überlastete Eisenbahnnetz in seiner Ausbauqualität sogar noch weit hinter den Stand von 1939 zurückgefallen .  Frau Präsidentin , da muss ein Blähhals am Werke sein .'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004f264f",
   "metadata": {},
   "source": [
    "## Replacing Double Full Stops by Single Full Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cec11e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'schäden erbringen .  Ja , wenn das für Sie alles bekannt war , wie konnte dann ein so kluger Mann wie Ihr Kanzlerkandidat von einem guten Investitionsstandort sprechen ? Diesen Zwiespalt und Widerspruch in Ihrer Argumentation verstehe ich nicht . Die Infrastruktur muss praktisch von Grund auf überholt werden . So ist das völlig überlastete Eisenbahnnetz in seiner Ausbauqualität sogar noch weit hinter den Stand von 1939 zurückgefallen .  Frau Präsidentin , da muss ein Blähhals am Werke sein .'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "def replace_double_full_stops(text):\n",
    "    text_clean = re.sub(\"\\.\\s*\\.\",\".\",text) # regex pattern matches two full stops separated by an arbitrary number of whitespaces\n",
    "    return text_clean\n",
    "\n",
    "replace_double_full_stops(teststring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a63351d",
   "metadata": {},
   "source": [
    "## Text Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a131e213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_length(text):\n",
    "    return len(text)\n",
    "\n",
    "text_length(teststring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f1cbf8",
   "metadata": {},
   "source": [
    "## Average Sentence Length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f407893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.66666666666667"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some tests to check nltk's ability of splitting a German text into sentences,\n",
    "# since not every full stop indicates the end of a sentence (abbreviations, ordinal numbers, ...)\n",
    "# problem: does not recognize German ordinal numbers, unless they are part of a date\n",
    "\n",
    "'''\n",
    "testsen1 = \"Herr Dr. Fischer, möchten Sie einen Tee?\" # pass\n",
    "testsen2 = \"Am 7. Januar hieß es noch, das Projekt wird sofort fertig sein, heute haben wir den 20. Januar!\" # pass\n",
    "testsen3 = \"Am 10. Tage wurde matplotlib geschaffen, und es wurde dunkel.\" # fail\n",
    "\n",
    "sentences = nltk.sent_tokenize(testsen3,language='german')\n",
    "print(len(sentences))\n",
    "'''\n",
    "\n",
    "def avg_sentence_length(text):\n",
    "    text_length = len(text)\n",
    "    sentences = nltk.sent_tokenize(text,language='german')\n",
    "    n_sentences = len(sentences)\n",
    "    return text_length/n_sentences\n",
    "\n",
    "# test to compare average sentence length calculated manually vs. with nltk -> pass\n",
    "\n",
    "'''\n",
    "testsplit = [\"schäden erbringen .\", \n",
    "           \"  Ja , wenn das für Sie alles bekannt war , wie konnte dann ein so kluger Mann wie Ihr Kanzlerkandidat von einem guten Investitionsstandort sprechen ?\",\n",
    "           \" Diesen Zwiespalt und Widerspruch in Ihrer Argumentation verstehe ich nicht .\",\n",
    "           \" Die Infrastruktur muss praktisch von Grund auf überholt werden .\",\n",
    "           \" So ist das völlig überlastete Eisenbahnnetz in seiner Ausbauqualität sogar noch weit hinter den Stand von 1939 zurückgefallen .\",\n",
    "           \"  Frau Präsidentin , da muss ein Blähhals am Werke sein .\"]\n",
    "\n",
    "testlist = [len(string) for string in testsplit]\n",
    "manual_calc = sum(testlist)/len(testlist)\n",
    "print(manual_calc, avg_sentence_length(teststring))\n",
    "'''\n",
    "\n",
    "avg_sentence_length(teststring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41affeb9",
   "metadata": {},
   "source": [
    "## Number of Profanities\n",
    "The profanities stem from a predefined list of unique strings, which also includes declinations.\n",
    "The list has been compiled from various online sources, and mostly comprises lighter profanities,\n",
    "as we would expect from the german Bundestag. However, standard severe profanities are also included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec48275a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profanities = ['Idiotin', 'Idioten', 'Möchtegern', 'Stümper', 'Hinterwäldlerin', 'Drecksack', 'Arschgeige', \n",
    "               'Arschloch', 'Volltrottel', 'unterbelichtet', 'Nörglerin', 'Schwachkopf', 'Faulpelz', \n",
    "               'Dreckskerl', 'Rowdy', 'hochnäsig', 'großmäulig', 'Scheiße', 'Deppen', 'verrückter', \n",
    "               'Backpfeifengesicht', 'abgefahrener', 'Lümmel', 'Ochse', 'Nörgeln', 'Depp', 'bescheuertster', \n",
    "               'Schnapsidee', 'Trottel', 'Nervensägen', 'blöde', 'Schlitzohr', 'Hanswürste', 'Zuhälter', \n",
    "               'Bauerntölpel', 'Hetzer', 'Schnauze', 'Dummköpfin', 'spinnen', 'Hetzerin', 'hochnäsige', \n",
    "               'spießig', 'Kacke', 'Ratte', 'Lackschuhpanter', 'Heuchlerin', 'dämlicher', 'beschissene', \n",
    "               'Arsch', 'Nervensäge', 'beschissen', 'Blödmann', 'Klugscheißer', 'Bastard', 'aufgeblasener', \n",
    "               'dummer', 'lahm', 'kotzen', 'altbacken', 'dümmstes', 'idiotisch', 'Schwachköpfe', 'scheiß', \n",
    "               'abgefahren', 'Dummkopf', 'dumme', 'Dummköpfe', 'Kleingeist', 'Hornochse', 'bescheuertstes', \n",
    "               'Schlange', 'Hackfresse', 'Armleuchter', 'Dreckschwein', 'hirnrissig', 'Verrückte', 'schlampig', \n",
    "               'kacke', 'Harzer', 'Pisser', 'blödes', 'Hund', 'spinnt', 'Hornochsen', 'Abschaum', 'Stinktier', \n",
    "               'Esel', 'Amateur', 'Großmaul', 'bescheuerte', 'verrückt', 'Alleswisser', 'blöd', 'Luder', \n",
    "               'schäbiger', 'Berufsrandalierer', 'Fresse', 'Stümperin', 'Zicke', 'aufgeblasene', 'Hanswurst', \n",
    "               'Sack', 'Teufel', 'Vollpfosten', 'Ziege', 'Galgenkandidat', 'Hurensohn', 'kindisch', 'Idiot', \n",
    "               'Dreckschweine', 'schmierig', 'Verrückter', 'Angeberin', 'Schwein', 'Hinterwäldler', 'verdammte', \n",
    "               'kleingeistig', 'aufgeblasen', 'Affe', 'bescheuertste', 'versifft', 'Bastarde', 'bieder', \n",
    "               'schäbig', 'Blöde', 'Schweine', 'Gangster', 'blödsinnig', 'dumm', 'stümperhaft', 'Arschlöcher', \n",
    "               'Spießer', 'verdammt', 'bescheuert', 'affig', 'Faulpelze', 'Angeber', 'Arschgeigen', 'Aasgeier', \n",
    "               'Besserwisser', 'Blöder', 'verrückte', 'Blödmänner', 'Heuchler', 'Nörgler', 'dämlich', 'dümmste', \n",
    "               'Hurensöhne', 'heuchlerisch', 'Pisse', 'bescheuerter', 'kleinkariert', 'Karnickel', 'kleinkarierte',\n",
    "               'Blähhals', 'verdammter', 'verdammtes']\n",
    "\n",
    "def count_profanities(text):\n",
    "    n_profanities = 0\n",
    "    tokens = nltk.word_tokenize(text, language='german')\n",
    "    for profanity in profanities:\n",
    "        n_profanities += tokens.count(profanity)\n",
    "    return n_profanities\n",
    "\n",
    "count_profanities(teststring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db1423c",
   "metadata": {},
   "source": [
    "## Type-Token-Ratio (#unique words / #total words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5c66f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def TTR(text):\n",
    "    tokens = nltk.word_tokenize(text, language='german')\n",
    "    tokens = [token.lower() for token in tokens if token.isalpha()]\n",
    "    n_total = len(tokens)\n",
    "    n_unique = len(set(tokens))\n",
    "    return n_unique/n_total\n",
    "\n",
    "TTR(\"Morgen morgen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e823b15b",
   "metadata": {},
   "source": [
    "## Readability Score\n",
    "Readability is calculated as Flesch-Reading-Ease for the German language.\n",
    "Interpretation: score of 0-30: very difficult, 30-50: difficult,\n",
    "50-60: medium/difficult, 60-70: medium, 70-80: medium/easy, 80-90: easy,\n",
    "90-100: very easy. See https://de.wikipedia.org/wiki/Lesbarkeitsindex#Flesch-Reading-Ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e8f821ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.2"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def readability(text):\n",
    "    textstat.set_lang(\"de\")\n",
    "    return textstat.flesch_reading_ease(text)\n",
    "\n",
    "readability(teststring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa9c613",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "<p> Based on the data set \"SentiWS\" (v.2.0), by R. Remus, U. Quasthoff & G. Heyer: SentiWS - a Publicly Available German-language Resource for Sentiment Analysis.\n",
    "In: Proceedings of the 7th International Language Resources and Evaluation (LREC'10), pp. 1168-1171, 2010.\n",
    "The data set is kindly provided by the University of Leipzig.\n",
    "</p>\n",
    "<p>\n",
    "Source: https://wortschatz.uni-leipzig.de/de/download\n",
    "</p>\n",
    "<p>\n",
    "The data set includes sentiment scores (range: -1 to +1) of many german words and their respective declinations,\n",
    "which are assigned the same sentiment score. We compute the sentiment score of a text as the average sentiment\n",
    "score of all words in that text, which have a sentiment score in the data set.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14229fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.21034000000000003\n"
     ]
    }
   ],
   "source": [
    "d = {} # create dictionary 'd' with the words as keys and their sentiment-scores as values\n",
    "\n",
    "with open(\"./SentiWS_v2.0/SentiWS_v2.0_Negative.txt\") as f: # read the file containing negative-sentiment words\n",
    "    for line in f:\n",
    "        split = re.split('\\||\\s|,',line) # split line at the delimiters '|', whitespace, and ','\n",
    "        keys = [split[0]] + split[3:-1] # make a list containing the the word and its declinations\n",
    "        value = float(split[2]) # sentiment score for the word and its declinations\n",
    "        for key in keys:\n",
    "            d[key] = value # add key:value pair to d for the word and its declinations\n",
    "\n",
    "# do exaclty the same for positive-sentiment words\n",
    "with open(\"./SentiWS_v2.0/SentiWS_v2.0_Positive.txt\") as g:\n",
    "    for line in g:\n",
    "        split = re.split('\\||\\s|,',line)\n",
    "        keys = [split[0]] + split[3:-1]\n",
    "        value = float(split[2])\n",
    "        for key in keys:\n",
    "            d[key] = value\n",
    "\n",
    "            \n",
    "# print(d['ausgezeichnet']) # conflict: the word is in the data base as adjective and as past-tense verb, with diffenrent sentiment scores\n",
    "            \n",
    "def sentiment(text):\n",
    "    tokens = nltk.word_tokenize(text, language='german')\n",
    "    tokens = [token.lower() for token in tokens if token.isalpha()]\n",
    "    sentiment_sum = 0 # sum up sentiment scores for tokens which have a sentiment score\n",
    "    sentiment_n = 0 # count the tokens which have a sentiment score\n",
    "    for token in tokens:\n",
    "        sentiment_score = d.get(token)\n",
    "        if sentiment_score != None:\n",
    "            sentiment_sum += sentiment_score\n",
    "            sentiment_n += 1\n",
    "    if sentiment_n > 0:\n",
    "        return sentiment_sum/sentiment_n # must be between -1 and 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "sentitest_1 = \"Vor ihm drängten sich und verschwanden leichthin die Häuser der Rue de Rome. Zur Linken öffneten die bedeckten Hallen ihre angerauchten Riesenglasdächer, das Auge tauchte tief in die ungeheure Halle für den Fernverkehr, welche die Baulichkeiten für die Post und das Wärmrohrmagazin von den anderen kleineren Hallen für den Verkehr nach Argenteuil, Versailles und der Ringbahn trennten. Rechts dagegen überwölbte der Pont de l'Europe mit seinem eisernen Stern die tiefe Furche, die man jenseits wieder erscheinen und von dort bis zum Tunnel von Les Batignolles heranreichen sah. Gerade unter dem Fenster, welches dieses ganze, mächtige Feld beherrschte, theilten sich die drei doppelten Schienenstränge, die unter der Brücke hervorkamen, in zahlreiche andere, die fächerartig auseinander liefen, und ihre vervielfachten, zahllosen, metallenen Arme verloren sich sofort unter den Glasdächern der Hallen. Die drei Weichenstellerhäuschen diesseits der Brückenbogen zeigten ihre öden Gärtchen. Mitten in dem konfusen Gewirr der auf den Schienen umherstehenden Waggons und Maschinen schimmerte ein rothes Signallicht verletzend durch den bleichen Tag.\"\n",
    "sentitest_2 = \"Warin war ein Graf zu Altorf und Ravensburg in Schwaben, sein Sohn hieß Isenbart und Irmentrut dessen Gemahlin. Es geschah, daß ein armes Weib unweit Altorf drei Kindlein auf ein Mal zur Welt brachte; als das Irmentrut die Gräfin hörte, rief sie aus: »Es ist unmöglich, daß dies Weib drei Kinder von einem Mann haben könne, ohne Ehbruch.« Dieses redete sie öffentlich vor Graf Isenbart ihrem Herrn und allem Hofgesinde »und diese Ehbrecherin verdiene nichts anders, als in einen Sack gesteckt und ertränkt zu werden.\"\n",
    "sentitest_3 = \"Lasst uns froh und munter sein! Und uns recht von Herzen freuen! Lustig, lustig, tralera-lera, Bald ist Nikolausabend da, Bald ist Nikolausabend da!\"\n",
    "    \n",
    "print(sentiment(sentitest_1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
